[
["index.html", "Data Science Campus Project Standards Preface", " Data Science Campus Project Standards Nathan Eastwood 2017-04-06 Preface The purpose of this document is to define correct coding standards and project best practices to be used within the Data Science Campus (DSC) at the Office for National Statistics (ONS). "],
["Intro.html", "1 Introduction", " 1 Introduction This is a test "],
["style.html", "2 Programming Styles 2.1 GitHub 2.2 R 2.3 Python", " 2 Programming Styles Make pretty code. 2.1 GitHub All GitHub repository names should follow the kebab-case naming convention and be in lower case. 2.2 R Generally we will be sticking to Hadley Wickham’s R Style Guide for all R code we write. Some important points to note are to try to stick to 80 characters per line (exceptions are made for .Rmd files or similar) and to use 2 spaces, not tabs! With regards to naming conventions, some people prefer snake_case where as others prefer camelCase; generally speaking either are fine so long as you and any collaborators are consistent with your code. 2.2.1 Tools The lintr package is designed to help you stick to certain coding conventions. lintr can be executed as standalone or as part of build. It can integrated into RStudio, emacs/ess, vim etc. Using lintr will ensure we are all conforming to the same coding standards. Additionally, lintr can be ran as part of your testthat tests. Quick formatting to code can be applied using the formatR package. The formatR package was designed to reformat R code to improve readability; the main workhorse is the function tidy_source(). Features include: long lines of code and comments are reorganized into appropriately shorter ones spaces and indent are added where necessary the number of spaces to indent the code (i.e. tab width) can be specified an else statement in a separate line without the leading } will be moved one line back = as an assignment operator can be replaced with &lt;- The goodpractice is useful for giving advice about good practices when building R packages. Advice includes functions and syntax to avoid, package structure, code complexity, code formatting (using lintr), etc. 2.3 Python The below are the most immediate features that ONS code should be expected to adhere to. The recommendations in Effective Python give a more in-depth idea of how to write good python code and align with our recommendations. 2.3.1 Style guide The following sections outline conditions on python code produced for sharing. 2.3.1.1 Spacing Tabs are illegal. All indentation should be in spaces and each indent should be either 2 or 4 spaces. 2.3.1.2 Line length No lines should exceed 80 characters. 2.3.1.3 Blank lines 1 line: There should be one line between blocks of code, the exceptions are where two lines are recommended. 2 lines: Start and end of function definitions, import blocks, headers, and class definitions should have 2 lines clearning them. Good import os class Goober(object): &quot;&quot;&quot;| docstrings are good docstrings are great &quot;&quot;&quot; def __init__(self): pass def main(): pass Bad import os class Goober(object): &quot;&quot;&quot;| docstrings are good docstrings are great &quot;&quot;&quot; def __init__(self): pass def main(): pass 2.3.1.4 Data declarations Elements must align, either in leading or following comma notation. Some examples: list_1 = [ elem_1, elem_2, elem_3 ] list_2 = [ elem_1 , elem_2 , elem_3 ] 2.3.1.5 List comprehensions There should be no more than 2 statements included in any list comprehension. If the comprehension is exceeding this length then break it out into a loop or multiple statements. It might make sense to you now but when somebody else comes to read it they will hate you if you don’t. 2.3.1.6 Exceptions Do not raise base exceptions. Create your own classes which extend them and manage your errors correctly. 2.3.1.7 Imports Imports should be grouped, at the top of your file and placed in the following order. Standard library PyPI available packages ONS modules and those local to your project 2.3.1.8 Type hinting Where possible use type hinting as perPEP484. It will make your code more verbose, easier to debug and handle when others come to inherit it. "],
["version-control.html", "3 Version Control 3.1 Commit best practices", " 3 Version Control Few software engineering projects will begin without some form of version control and data science should be no different. Version control software allows us to track the three Ws: Who made Which change, and Why? There are various different version control tools such as Git, SVN and Mercurial, however within the Data Science Campus we use git as our version control software of choice. Git can be used locally on a single machine, on many networked machines or connected to many online repository services such as GitHub, GitLab and BitBucket. Each of these services provides hosting for your version control repository, and makes the code open and easy to share with the world, or if necessary, private and shared with the Campus team only. We use GitHub within the Campus and have an organisation account which allows us to use private repositories, please speak to another member of staff about getting help in joining the organisation. 3.1 Commit best practices Ideally, each commit should be minimal but complete. They should aim to solve a single specific problem with your code. This makes commits that you make much easier to understand but it also makes it easier to undo commits should you make an error. Leaving all changes to be committed at the end of the day is a bad idea as rather than being able to undo a single issue, you may lose an entire day’s work to solve your problem. When you think you have solved a bug, it is always a good idea to include a test to confirm you are correct. Each commit message should be concise but present a clear message about what the commit achieved. There should be enough detail so you can remember (and understand) what was done. Ideally you should describe the why but not the what. Figure 3.1: Try to keep git commit messages as informative as possible Sticking to these standards will make it much easier to work with others. For example, if two people have changed the same file in the same place, it’ll be easier to resolve conflicts if the commits are small and it’s clear why each change was made and project newcomers can more easily understand the history by reading the commit logs. More importantly, if you can figure out exactly when a bug was introduced, you can easily understand what you were doing (and why!). Some really good advice is: You might think that because no one else will ever look at your repo, that writing good commit messages is not worth the effort. But keep in mind that you have one very important collaborator: future-you! If you spend a little time now polishing your commit messages, future-you will thank you if and when they need to do a post-mortem on a bug. – Hadley Wickham "],
["docs.html", "4 Code Documentation 4.1 R 4.2 Python", " 4 Code Documentation Documenting our code is an essential part of what we do. We should document our code to the point where someone else can view it and understand how it works and why. Documentation is also useful for future-you (so you remember what your functions were supposed to do), and for developers extending your code. 4.1 R When documenting functions in R, it is standard practice to use the Roxygen2 package which not only helps to generate your manual (.Rd) files, but also manages your NAMESPACE file and the Collate field of the DESCRIPTION file. This integrates really nicely with R package building. For more information on Roxygen2, see the Manual section of the R packages book and the vignettes on the CRAN package page. 4.2 Python "],
["tests.html", "5 Code Testing 5.1 R 5.2 Python", " 5 Code Testing In functional programming, code is designed to be reused again and again with different inputs, making for simpler code that is easier to understand and audit. Writing functions allows us to more easily document our code meaning that others can use it without too much hassle. It also means that we can build tests to ensure the code continues to work as expected when we make changes to it. Everytime you write a new function, you should strive to write tests for that function. In fact, some people use a test driven development approach whereby tests are written first and a function is written second to pass those tests. In the case a bug is discovered with a function, a test should always be written to ensure that bug is not reintroduced at some point in the future - you are essentially protecting yourself from future you’s mistakes. 5.1 R There are different packages that help with writing and running tests in R such as RUnit and testthat. It is the latter that is generally recommended. More information about testthat can be found in the R packages book. 5.2 Python nosetools pytest "],
["automated-testing.html", "6 Automated Testing", " 6 Automated Testing foo bar "],
["code-coverage.html", "7 Code Coverage 7.1 Coverage Services 7.2 R", " 7 Code Coverage Writing tests for our code we can ensure that it works as expected and check when changes to that code break pre-existing functionality. But how do we know whether we have tested each possible scenario for our functions? How do we know which lines of code are ran during our tests? This is where code coverage comes in. Code coverage is a measure of the amount of code being exercised by a set of tests. It is an indirect measure of test quality and completeness. For example, in the code below, we can see that lines 112-115 and 117-120 are not explicitly tested. In this case, we probably don’t need to worry very much, but on other occasions this might prompt us to write more tests. Figure 7.1: Code Coverage Measuring code coverage allows developers to asses their progress in quality checking their own (or their collaborators) code. Measuring code coverage allows code consumers to have confidence in the measures taken by the package authors to verify high code quality. – Jim Hester 7.1 Coverage Services Codecov Coveralls 7.2 R covr allows the user to track and report code coverage for your package and (optionally) upload the results to a coverage service like Codecov or Coveralls. covr works with both RUnit and testthat, though we are using testthat for our tests. covr provides three functions to calculate test coverage: package_coverage() performs coverage calculation on an R package (unit tests must be contained in the “tests” directory) file_coverage() performs coverage calculation on one or more R scripts by executing one or more R scripts. function_coverage() performs coverage calculation on a single named function, using an expression provided Please read the documentation for more information on how covr works. "],
["package.html", "8 Code Packaging 8.1 R 8.2 Python", " 8 Code Packaging When writing code for a project, that code should ideally be held within a self contained package or series of packages. This helps to manage dependencies on other packages, code testing, documentation and more. 8.1 R For R, there is one major resource that you should make yourself familiar with: http://r-pkgs.had.co.nz/. This book should cover all the essentials you will need to know in order to write an R package. Once you have mastered this book, you may wish to consider the Writing R Extensions manual, though this is a heavy read. When writing R packages, you should continually check the results of your R CMD check and remove any NOTEs, WARNINGs and ERRORs, where possible. We should not ship broken code! 8.2 Python "],
["deps.html", "9 Dependency Management 9.1 Docker 9.2 R 9.3 Python", " 9 Dependency Management Dependency management systems are incredibly important, particularly in the world of analysis. Whenever we produce some code to perform statistical analysis or machine learning, we need to be able to recreate those results exactly. This could be the day after or the year after and we need to know which versions of which packages we must have installed on our machine. Updates to packages can produce breaking changes and our code may produce slightly different results, or worse yet, not run at all. Then installing a specific packages for a certain project may make code on other projects break. That results can change so much with different pkg versions is scary (and ignored by many) https://t.co/wn5x3UBgQz #rstats #reproducibility pic.twitter.com/Jp4ASOKC81 — F Rodriguez-Sanchez (@frod_san) 29 March 2017 Moreover, you may be presented with someone else’s code but without them explicitly stating which packages you need, it is not always obvious, and even then you still have the manual challenge of installing the correct versions of each package yourself. These packages may then end up being globally installed when you don’t need them for any other project, therefore clogging up your system. 9.1 Docker Rocker 9.2 R Keeping track of dependencies in R can be a chore, particularly when using lots of different packages such as those belonging to the tidyverse. There are however different packages which aim to help with this. 9.2.1 DESCRIPTION file This is the most basic way of maintanining dependencies in R, though it is not recommended - it is only part of the dependency management system you should employ. Each R package will have a DESCRIPTION file which should contain a list of packages your package Depends on, Imports and Suggests. You can specify certain versions within for each of these. 9.2.2 NAMESPACE file Dependencies in R packages are maintained using the NAMESPACE file. You should never write these files by hand as they are tedious to maintain and this approach is prone to error. Instead, you should consider using the Roxygen2 package which is detailed in the Code Documentation section of this report. 9.2.3 packrat packrat is a dependency management system for R. Use packrat to make your R projects more: Isolated: Installing a new or updated package for one project won’t break your other projects, and vice versa. That’s because packrat gives each project its own private package library. Portable: Easily transport your projects from one computer to another, even across different platforms. packrat makes it easy to install the packages your project depends on. Reproducible: packrat records the exact package versions you depend on, and ensures those exact versions are the ones that get installed wherever you go. See the project page for more information. 9.2.4 pkgsnap pkgsnap is a more lightweight alternative to packrat which allows you to backup and restore certain CRAN package versions. pkgsnap will create a snapshot of your installed CRAN packages with snap(), and then use restore() on another system to recreate exactly the same environment. Unfortunately pkgsnap isn’t heavily developed. 9.3 Python "]
]
